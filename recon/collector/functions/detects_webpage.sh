#############################################################
#                                                           #
# This file is an essential part of collector's execution!  #
# And is responsible to get the functions:                  #
#   * webapp_alive                                          #
#                                                           #
############################################################# 

webapp_alive(){
    if [ -d "${report_dir}" ]; then
        if [ -s "${report_dir}/domains_alive.txt" ]; then
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Testing subdomains to know if it is or have web application... "

            if [ -n "${use_proxy}" ] && [ "${use_proxy}" == "yes" ]; then
                proxy_port=8118
                proxy_ports=$("${docker_bin}" ps -a | grep -E "privoxy.*0.0.0.0" | awk '{print $13}' | sed -e 's/-.*$//' | awk -F':' '{print $2}')

                while [[ "${proxy_ports[@]}" =~ "${proxy_port}" ]]; do
                    (( proxy_port+=1 ))
                done

                "${docker_bin}" run -d --rm --name "hosts_alive_detect" -p "${proxy_port}:8118" privoxy > /dev/null

                if [ "$(${docker_bin} ps -a | grep -E hosts_alive_detect | awk '{print $14}')" == "hosts_alive_detect" ]; then
                    proxy="$(docker inspect --format '{{ .NetworkSettings.IPAddress }}' "hosts_alive_detect"):${proxy_port}"
                fi
                [[ -n "${proxy}" ]] && alias curl="curl --proxy ${proxy}"
            fi

            for subdomain in $(cat "${report_dir}/domains_alive.txt"); do
                for port in "${web_port_detect[@]}"; do
                    subdomain_http_status_check=$(curl "${curl_options[@]}" -L -w "%{response_code}\n" "http://${subdomain}:${port}" -o /dev/null)
                    subdomain_https_status_check=$(curl "${curl_options[@]}" -L -w "%{response_code}\n" "https://${subdomain}:${port}" -o /dev/null)
                    if [[ "${subdomain_http_status_check}" -ne 400 ]] && [[ "${subdomain_http_status_check}" -ne 000 ]]; then
                        echo -e "http://${subdomain}:${port}\t${subdomain_http_status_check}" >> "${report_dir}/domains_web_status.txt"
                    fi
                    if [[ "${subdomain_https_status_check}" -ne 400 ]] && [[ "${subdomain_https_status_check}" -ne 000 ]]; then
                        echo -e "https://${subdomain}:${port}\t${subdomain_https_status_check}" >> "${report_dir}/domains_web_status.txt"
                    fi
                done
            done

            if [ "$(${docker_bin} ps -a | grep -E hosts_alive_detect | awk '{print $14}')" == "hosts_alive_detect" ]; then
                unalias curl
                unset proxy
                unset proxy_port
                unset proxy_ports
                "${docker_bin}" stop "hosts_alive_detect" > /dev/null
            fi

            if [ -s "${report_dir}/domains_web_status.txt" ]; then
                echo "Done!"
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Separating web applications according to the HTTP Status Code defined in collector.cfg... "
                sed -i 's/\/\/$// ; s/:443// ; s/:80$// ; s/:80\t/\t/ ; s/\(:80\)\(\/\)/\2/ ; s/:\/$// ; s/\(\.\)\([[:alpha:]]*\)\(\/$\)/\1\2/' "${report_dir}/domains_web_status.txt"
                for page_status in "${web_get_status[@]}"; do
                    grep -E "${page_status}$" "${report_dir}/domains_web_status.txt" | awk '{print $1}' >> "${report_dir}/domains_web.txt"
                done
            else
                echo "Fail!"
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Something got wrong during web check status!"
                exit 1
            fi
            
            if [ -s "${report_dir}/domains_web.txt" ]; then
                echo "Done!"
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Separating infrastructure from web application... "
                if cp "${report_dir}/domains_alive.txt" "${report_dir}/domains_infrastructure.txt"; then
                    while IFS= read -r line; do
                        subdomain=$(echo "${line}" | sed -e "s/http:\/\///" -e "s/https:\/\///" | awk -F":" '{print $1}' | awk -F"/" '{print $1}')
                        if grep -q "${subdomain}" "${report_dir}/domains_infrastructure.txt" 2> ${log_dir}/recon_domain_error_${date_recon}.log ; then
                            sed -i "/^${subdomain}$/d" "${report_dir}/domains_infrastructure.txt"
                        else
                            continue
                        fi
                        unset subdomain
                    done < "${report_dir}/domains_web.txt"
                    echo "Done!"
                else
                    echo "Fail!"
                    echo "Could not create file for infrastructure domains, something went wrong."
                    exit 1
                fi            
            else
                echo "Fail!"
                echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} We probably didn't have any application with HTTP Status Code defined in collector.cfg, something is wrong!"
                exit 1
            fi
            
            if [ -s "${report_dir}/domains_web_status.txt" ] && [ -s "${report_dir}/domains_infrastructure.txt" ]; then
                echo -e "\t We have $(awk '{print $1}' "${report_dir}/domains_web_status.txt" | sed -e 's/^http.*\/\/// ; s/:.*$//' | awk -F'/' '{print $1}' | sort -u | wc -l) Web Applications URLs."
                echo -e "\t Probably we have $(wc -l "${report_dir}/domains_infrastructure.txt" | awk '{print $1}') Infrastructure domains."
            fi

        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} webapp_alive function error: the ${report_dir}/domains_alive.txt does not exist or is empty."
            exit 1
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Make sure the directories structure was created. Stopping the script."
        exit 1
    fi
}
